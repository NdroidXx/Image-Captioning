# Image-Captioning

The project uses pre-trained models from hugging face to generate captions for the image provided by the user.

## The Models Used Are:
- ViT + GPT-2 : https://huggingface.co/nlpconnect/vit-gpt2-image-captioning
- BLIP - https://huggingface.co/Salesforce/blip-image-captioning-large
- Library Used to deploy is StreamLit

## Usage 
```
streamlit run Final.py
or
streamlit run Deploy_BLIP.py
or 
streamlit run Deploy_ViT.py
```
